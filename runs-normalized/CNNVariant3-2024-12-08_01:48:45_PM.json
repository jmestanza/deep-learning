{
    "optimizer": [
        "Adam (",
        "Parameter Group 0",
        "    amsgrad: False",
        "    betas: (0.9, 0.999)",
        "    capturable: False",
        "    differentiable: False",
        "    eps: 1e-08",
        "    foreach: None",
        "    fused: None",
        "    lr: 0.001",
        "    maximize: False",
        "    weight_decay: 0",
        ")"
    ],
    "criterion": [
        "CrossEntropyLoss()"
    ],
    "model": [
        "CNNVariant3(",
        "  (conv1): Sequential(",
        "    (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1))",
        "    (1): Tanh()",
        "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)",
        "  )",
        "  (drop): Dropout2d(p=0.7, inplace=False)",
        "  (conv2): Sequential(",
        "    (0): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1))",
        "    (1): Tanh()",
        "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)",
        "  )",
        "  (conv3): Sequential(",
        "    (0): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))",
        "    (1): Tanh()",
        "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)",
        "  )",
        "  (fc): Linear(in_features=64, out_features=10, bias=True)",
        ")"
    ],
    "epoch_t_loss": [
        1.5625511475844678,
        1.285219134488848,
        1.2441359569014772,
        1.222840409797392,
        1.20938973220935,
        1.1957841435475136,
        1.1812954539937506,
        1.172977757606425,
        1.1694095226874484,
        1.1637781493063928,
        1.1668147452350364,
        1.1572560648928318,
        1.1639642552780445,
        1.1512234392704994,
        1.1449727287043387
    ],
    "epoch_v_loss": [
        0.8668384859516363,
        0.7754405355377562,
        0.733122946919909,
        0.7075299138476134,
        0.6894924942475216,
        0.6778649224597177,
        0.676237695156389,
        0.6622836650556819,
        0.6496659619793012,
        0.6469001394168586,
        0.6397978443249016,
        0.632342250863458,
        0.6298459250076561,
        0.6263035290939792,
        0.6237695536036401
    ],
    "epoch_t_acc": [
        0.4299207089552239,
        0.5142757196162047,
        0.5264525586353944,
        0.5323494136460555,
        0.5363472814498934,
        0.5416444562899787,
        0.548890591684435,
        0.5518889925373134,
        0.552755197228145,
        0.5538879264392325,
        0.5530383795309168,
        0.5581689765458422,
        0.5534215085287847,
        0.5599513592750534,
        0.5641824360341151
    ],
    "epoch_v_acc": [
        0.6808320063694268,
        0.714171974522293,
        0.7307921974522293,
        0.7391520700636943,
        0.7441281847133758,
        0.7471138535031847,
        0.7446257961783439,
        0.7513933121019108,
        0.7580613057324841,
        0.7536823248407644,
        0.7565684713375797,
        0.759952229299363,
        0.7597531847133758,
        0.7601512738853503,
        0.7628383757961783
    ],
    "t_epoch": [
        21.941354036331177,
        22.738200902938843,
        22.42585563659668,
        22.71139621734619,
        21.939289569854736,
        22.241393089294434,
        22.425457239151,
        23.589519739151,
        22.800395011901855,
        22.753451347351074,
        22.96557855606079,
        23.21005368232727,
        22.8629469871521,
        21.90704846382141,
        22.66702914237976
    ],
    "trainable_params": 1334,
    "params_table": [
        "+----------------+------------+",
        "|    Modules     | Parameters |",
        "+----------------+------------+",
        "| conv1.0.weight |     16     |",
        "|  conv1.0.bias  |     4      |",
        "| conv2.0.weight |    128     |",
        "|  conv2.0.bias  |     8      |",
        "| conv3.0.weight |    512     |",
        "|  conv3.0.bias  |     16     |",
        "|   fc.weight    |    640     |",
        "|    fc.bias     |     10     |",
        "+----------------+------------+"
    ]
}